import tabulate
import csv
import argparse
from datetime import datetime
import random
import matplotlib.pyplot as plt
from matplotlib.lines import Line2D
from matplotlib.patches import Patch
from matplotlib import cm
import matplotlib.lines as mlines
import matplotlib.markers
import string
import matplotlib

parser = argparse.ArgumentParser(
    description="Convert a csv file generated by process_output.py to a scatter plot input csv."
)
parser.add_argument("input", type=str, help="location of input csv file")
parser.add_argument("compx", type=str, help="method on x axis")
parser.add_argument("compy", type=str, help="method(s) on y axis")
parser.add_argument("labelx", type=str, help="label on x axis")
parser.add_argument("labely", type=str, help="label on y axis")
parser.add_argument(
    "--output-csv",
    type=str,
    help="location of output csv file",
)
parser.add_argument(
    "--output-pdf",
    type=str,
    help="location of output pdf file",
)
parser.add_argument(
    "--comp-field", help="fields to compare", type=str, default="BigStep"
)
parser.add_argument(
    "--compare-by", help="fields to compare", type=str, default="Time (wall)"
)
parser.add_argument(
    "--ignore", help="fields to ignore", type=str, default=None
)
parser.add_argument(
    "--filter", help="key/values to only include e.g. a:x,y;b:z", type=str, default=None
)
parser.add_argument(
    "--one-vs-all", help="creates a one-vs-all plot", type=bool, default=False
)
parser.add_argument(
    "--separate-legend", help="saves legend in different pdf", type=int, default=0
)
# parser.add_argument(
#     "--symbols", help="symbols instead of letters", type=bool, default=False
# )

parser.add_argument(
    "--min", help="min shown value (power of 10)", type=int, default=-1
)
parser.add_argument(
    "--max", help="max shown value (power of 10)", type=int, default=5
)
parser.add_argument(
    "--figsize", help="figsize (fig is a square)", type=int, default=7
)
parser.add_argument(
    "--title", help="add title", type=int, default=0
)

args = parser.parse_args()

MIN_VALUE = 10**args.min
ACTUAL_MIN_VALUE = 10**(args.min - .2)
MAX_VALUE = 10**args.max

GEQ_VALUE = 2*MAX_VALUE
TO_VALUE = 8 * MAX_VALUE

matplotlib.rcParams.update({"font.size": 16})

color_map = {}
marker_map = {}
hatch_map = {}

benchmark_map = {}
model_map = {}
with open(args.input) as csvfile:
    reader = csv.DictReader(csvfile)
    for row in reader:
        # hermans are different prism files, but we want to treat them as the
        # same in this plot
        if row["Model"].startswith("herman_random_pass"):
            row["Model"] = "hermanspeed"
        elif row["Model"].startswith("herman"):
            row["Model"] = "herman"
        skip = False
        if args.filter != None:
            for keyvalue in args.filter.split(";"):
                key = keyvalue.split(":")[0]
                values = keyvalue.split(":")[1].split("!")
                values = [row[value[1:]] if value.startswith("%") else value for value in values]
                if row[key] not in values:
                    skip = True
                    break
        if skip:
            continue
        join_params = ["Model", "Const", "Mem", "Prop", "RobustPLA", "BigStep", "Simple"]
        if args.ignore:
            for x in args.ignore.split(","):
                join_params.remove(x)
        if args.comp_field in join_params:
            join_params.remove(args.comp_field)
        benchmark_id = "-".join([row[x] for x in join_params])
        if benchmark_id not in benchmark_map:
            benchmark_map[benchmark_id] = []
        benchmark_map[benchmark_id].append(row)
        model_map[row["Model"]] = 1


benchmark_map_averaged = {}
for benchmark_id in benchmark_map:
    benchmarks = benchmark_map[benchmark_id]
    keys = benchmarks[0].keys()
    benchmark_buckets = []
    for benchmark in benchmarks:
        found_bucket = False
        for benchmark_bucket in benchmark_buckets:
            benchmark2 = benchmark_bucket[0]
            belongs_into_bucket = True
            for key in keys:
                if (
                    key != args.compare_by
                    and key != "Regions"
                    and benchmark2[key] != benchmark[key]
                ):
                    belongs_into_bucket = False
                    break
            if belongs_into_bucket:
                found_bucket = True
                benchmark_bucket.append(benchmark)
        if not found_bucket:
            benchmark_buckets.append([benchmark])
    # Average buckets
    benchmark_map_averaged[benchmark_id] = []
    for benchmark_bucket in benchmark_buckets:
        times = []
        founds = []
        avg_time = None
        avg_found = None
        for benchmark in benchmark_bucket:
            times.append(benchmark[args.compare_by])
            founds.append(benchmark["Regions"])
        
        if "N/A" in times or "ERR" in times or "TO" in times:
            if len(set(times)) > 1:
                print(
                    "In this benchmark, some timed out, but some didn't:",
                    benchmark_bucket,
                )
                avg_time = "N/A"
                avg_found = "N/A"
            else:
                avg_time = times[0]
                avg_found = times[0]
        else:
            avg_time = sum([float(x) for x in times]) / len(times)
            avg_found = sum([float(x) for x in founds]) / len(founds)
        first_benchmark = benchmark_bucket[0].copy()
        first_benchmark[args.compare_by] = avg_time
        first_benchmark["Regions"] = avg_found
        benchmark_map_averaged[benchmark_id].append(first_benchmark)
benchmark_map = benchmark_map_averaged


# Make a scatter plot!
x = []
y = []
colors = []
markers = []
hatches = []

if args.one_vs_all:
    NUM_COLORS = len(args.compy.split(","))
else:
    NUM_COLORS = len(model_map.keys()) * len(args.compy.split(","))
# color_cycle = [cm(0)] * 1000
cm = plt.get_cmap('nipy_spectral')
cm = plt.get_cmap("brg")
color_cycle = [cm(1.*i/NUM_COLORS) for i in range(NUM_COLORS)]
marker_cycle = []
# if args.one_vs_all:
#     marker_cycle = ["o"] * 1000
hatch_cycle = [None] * len(color_cycle)
# for letter in (list(string.ascii_lowercase)) * 10:
#     marker_cycle.append("$" + letter + "$")

marker_table = {
    "nrp": "P",
    "nand" : "X",
    "herman": "*",
    "refuel": "s"
}


i = 0


def marker_discriminator(compy_benchmark):
    if args.one_vs_all:
        return compy_benchmark[args.comp_field]
    return compy_benchmark["Model"]

# print(benchmark_map)
for benchmark_id in benchmark_map:
    benchmarks = benchmark_map[benchmark_id]
    compx_benchmark = None
    compy_benchmarks = []
    model = None
    for benchmark in benchmarks:
        if benchmark[args.comp_field] == args.compx:
            
            compx_benchmark = benchmark
        if benchmark[args.comp_field] in args.compy.split(","):
            compy_benchmarks.append(benchmark)
        model = benchmark["Model"]
    if compx_benchmark == None or compy_benchmarks == [] or model == None:
        print("Warning: Not both methods exist in benchmark " + benchmark_id)
        continue
    for compy_benchmark in compy_benchmarks:
        if marker_discriminator(compy_benchmark) not in color_map:
            color_map[marker_discriminator(compy_benchmark)] = color_cycle[i]
            if compy_benchmark["Model"] in marker_table:
                marker_map[marker_discriminator(compy_benchmark)] = marker_table[compy_benchmark["Model"]]
            else:
                marker_map[marker_discriminator(compy_benchmark)] = "o"
            hatch_map[marker_discriminator(compy_benchmark)] = hatch_cycle[i]
            i += 1
    # output_table.append(["pdtmc", benchmark_id, model, color_map[model], compx_benchmark["Time"], compy_benchmark["Time"]])

    def time_to_int(time):
        if time == "N/A" or time == "ERR" or time == "TO":
            return TO_VALUE
        if float(time) > MAX_VALUE:
            return GEQ_VALUE
        if float(time) < MIN_VALUE:
            return MIN_VALUE
        return float(time)

    for compy_benchmark in compy_benchmarks:
        x.append(time_to_int(compx_benchmark[args.compare_by]))
        y.append(time_to_int(compy_benchmark[args.compare_by]))
        colors.append(color_map[marker_discriminator(compy_benchmark)])
        markers.append(marker_map[marker_discriminator(compy_benchmark)])
        hatches.append(hatch_map[marker_discriminator(compy_benchmark)])

# with open(args.output_csv, 'w') as csvfile:
#     writer = csv.writer(csvfile)
#     writer.writerows(output_table)

fig = plt.figure(figsize=(args.figsize, args.figsize))
ax = plt.gca()
ax.set_aspect("equal")
custom_legend_plots = []
custom_legend_labels = []
for model in color_map:
    marker = plt.scatter(
        [0],
        [0],
        s=[160],
        marker=marker_map[model],
        color=color_map[model],
        hatch=hatch_map[model],
    )
    custom_legend_plots.append(marker)
    custom_legend_labels.append(model)

line = mlines.Line2D(
    [ACTUAL_MIN_VALUE, MAX_VALUE], [ACTUAL_MIN_VALUE, MAX_VALUE], color="black", ls="-"
)
ax.add_line(line)
line2 = mlines.Line2D(
    [ACTUAL_MIN_VALUE, MAX_VALUE / 10], [ACTUAL_MIN_VALUE * 10, MAX_VALUE], color="black", ls="--"
)
ax.add_line(line2)
line3 = mlines.Line2D(
    [ACTUAL_MIN_VALUE, MAX_VALUE / 100], [ACTUAL_MIN_VALUE * 100, MAX_VALUE], color="black", ls="--"
)
ax.add_line(line3)

to_line1 = mlines.Line2D([0, GEQ_VALUE], [GEQ_VALUE, GEQ_VALUE], color="gray", ls="-")
ax.add_line(to_line1)
to_line2 = mlines.Line2D([GEQ_VALUE, GEQ_VALUE], [GEQ_VALUE, 0], color="gray", ls="-")
ax.add_line(to_line2)

err_line1 = mlines.Line2D([0, TO_VALUE], [TO_VALUE, TO_VALUE], color="gray", ls="-")
ax.add_line(err_line1)
err_line2 = mlines.Line2D([TO_VALUE, TO_VALUE], [TO_VALUE, 0], color="gray", ls="-")
ax.add_line(err_line2)

plt.draw()

for i in range(len(x)):
    ax.scatter(
        [x[i]],
        [y[i]],
        c=[colors[i]],
        marker=markers[i],
        s=[100],
        zorder=1000,
        alpha=0.7,
        hatch=hatches[i],
    )
    # if args.one_vs_all:
    # else:
    #     ax.scatter([x[i]], [y[i]], c=[colors[i]], marker=markers[i], s=[160], zorder=1000, alpha=1)
ax.set_yscale("log")
ax.set_xscale("log")
ax.set_xlim([ACTUAL_MIN_VALUE, TO_VALUE + TO_VALUE])
ax.set_ylim([ACTUAL_MIN_VALUE, TO_VALUE + TO_VALUE])
    
plt.text(ACTUAL_MIN_VALUE * 2, GEQ_VALUE / 2, f"Better for {args.labelx}", fontstyle="italic", alpha=0.5, fontsize=10)
plt.text(GEQ_VALUE / 2, ACTUAL_MIN_VALUE * 2, f"Better for {args.labely}", fontstyle="italic", alpha=0.5, horizontalalignment="right", fontsize=10)


if not args.separate_legend:
    leg = ax.legend(custom_legend_plots, custom_legend_labels, bbox_to_anchor=(1.04, 1), borderaxespad=0)


ax.spines["right"].set_visible(False)
ax.spines["top"].set_visible(False)

locs, labels = plt.xticks()


numbers = [10**x for x in range(args.min, args.max)]
locs = numbers + [GEQ_VALUE, TO_VALUE]

number_labels = [f"$10^{{{x}}}$" for x in range(args.min, args.max)]
labels = ["$\\leq$" + number_labels[0]] + number_labels[1:] + ["$\\geq$"f"$10^{{{args.max}}}$", "TO"]

plt.xticks(locs, labels, rotation=45, ha="right")
plt.yticks(locs, labels)
ax.set_xlabel(args.labelx, labelpad=0)
ax.set_ylabel(args.labely, labelpad=0)

if args.title:
    plt.title(f"{args.compare_by}, {args.filter.replace(':', '=') if args.filter else ''}")

plt.savefig(args.output_pdf, bbox_inches="tight")

if args.separate_legend:
    figlegend = plt.figure(figsize=(3, args.figsize + 4))
    leg = figlegend.legend(custom_legend_plots, custom_legend_labels)
    figlegend.tight_layout()
    figlegend.savefig(args.output_pdf.replace(".", "-legend."))
